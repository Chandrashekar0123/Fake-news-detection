# -*- coding: utf-8 -*-
"""Fake-news-detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P0IYYSuZM89NOsmU9lF-6EuREBNBHIB3
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
import re
import joblib
import string

# Load datasets
fake = pd.read_csv("Fake.csv")
true = pd.read_csv("True.csv")

print(fake.head())

true.head()

# Function to show details
def dataset_info(name, df):
    print(f"ðŸ“Š Dataset: {name}")
    print("="*50)
    print("Shape (rows, columns):", df.shape)
    print("\nColumn Names:", df.columns.tolist())
    print("\nData Types:\n", df.dtypes)
    print("\nMissing Values:\n", df.isnull().sum())
    print("\nFirst 5 Rows:\n", df.head())
    print("\n" + "="*50 + "\n")

# Show details for both
dataset_info("Fake News", fake)

dataset_info("True News", true)

fake["class"] = 0
true['class'] = 1

data = pd.concat([fake, true], axis=0)

data

data = data.drop(['title', 'subject', 'date'], axis = 1)

data

data.reset_index(inplace = True)

data.drop('index', axis = 1, inplace = True)

data.head()

# Text cleaning function
def clean_text(text):
    text = text.lower()  # lowercase
    text = re.sub(r'\[.*?\]', "", text)  # remove text in brackets
    text = re.sub(r"\W", " ", text)  # remove non-word characters
    text = re.sub(r"https?://\S+|www\.\S+", "", text)  # remove links
    text = re.sub(r"<.*?>+", "", text)  # remove HTML tags
    text = re.sub(r"[%s]" % re.escape(string.punctuation), "", text)  # remove punctuation
    text = re.sub(r"\n", " ", text)  # remove newlines
    text = re.sub(r"\w*\d\w*", "", text)  # remove words containing numbers
    return text

# Clean the text
data["text"] = data["text"].apply(clean_text)

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score

# Features and labels
x = data["text"]
y = data["class"]

# Train-test split
xtrain, xtest, ytrain, ytest = train_test_split(
    x, y, test_size=0.25, random_state=42
)

# ---- Vectorization ----
vectorizer = TfidfVectorizer()
xv_train = vectorizer.fit_transform(xtrain)
xv_test = vectorizer.transform(xtest)

# ---- Model ----
lr = LogisticRegression(max_iter=200)   # increase iterations to converge
lr.fit(xv_train, ytrain)

# ---- Prediction ----
prediction = lr.predict(xv_test)

# ---- Evaluation ----
print("Accuracy:", accuracy_score(ytest, prediction))

print("\nClassification Report:\n", classification_report(ytest, prediction))

joblib.dump(vectorizer, 'vectorizer.jb')
joblib.dump(lr, 'lr_model.jb')

